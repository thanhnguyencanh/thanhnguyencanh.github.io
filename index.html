<!DOCTYPE HTML>
<script>
function showMore() {

    var listData = Array.prototype.slice.call(document.querySelectorAll('#dataList li:not(.shown)')).slice(0, 9);

  for (var i=0; i < listData.length; i++)
  {
    listData[i].className  = 'shown';
    listData[i].style.display = 'list-item';
  }
  switchButtons();
}


function switchButtons() {
    var hiddenElements = Array.prototype.slice.call(document.querySelectorAll('#dataList li:not(.shown)'));
  if(hiddenElements.length == 0)
  {
    document.getElementById('moreButton').style.display = 'none';
  }
  else
  {
    document.getElementById('moreButton').style.display = 'block';
  }

  var shownElements = Array.prototype.slice.call(document.querySelectorAll('#dataList li:not(.hidden)'));
  if(shownElements.length == 0)
  {
    document.getElementById('lessButton').style.display = 'none';
  }
  else
  {
    document.getElementById('lessButton').style.display = 'block';
  }
}

onload= function(){
    showMore();
}
</script>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Thanh Nguyen Canh</title>
  
  <meta name="author" content="Thanh Nguyen Canh">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Thanh Nguyen Canh</name>
              </p>
              <p>I am a PhD student in the <a href="https://www.jaist.ac.jp/english/areas/information-science.html"> School of Information Science </a> at <a href="https://www.jaist.ac.jp/english/">Japan Advanced Institute of Science and Technology</a>. 
                I work at the <a href="https://www.jaist.ac.jp/robot/"> Robotics Laboratory</a> and am fortunate to be advised by Prof. <a href="https://fp.jaist.ac.jp/public/Default2.aspx?id=352&l=1">Chong Nak Young</a>
                on 3D Active Semantic SLAM.
              </p>
              <p>
                  I obtained my Master degree from the <a href="https://www.jaist.ac.jp/english/areas/information-science.html"> School of Information Science </a> at <a href="https://www.jaist.ac.jp/english/"> JAIST</a>, Japan 
                  and B.S. degree in Roboitics Engineering from <a href="https://uet.vnu.edu.vn/en/"> University of Engineering and Technology, Vietnam National University, Vietnam </a>.
                  I worked on real-time semantic-aware simultaneous localization and mapping (SLAM) for Unmanned Aerial Vehicle (UAV). 
                  During my Master, I am grateful to collaborate with Prof. <a href="https://sites.google.com/site/xiemhoang/home?authuser=0"> Xiem HoangVan</a>,
                  Prof. <a href="https://aelibol.github.io/"> Armagan Elibol</a>,
                  Prof. <a href="https://sites.google.com/view/manhduongphung/home?authuser=0"> Manh Duong Phung</a> and
                  Prof. <a href="https://scholar.google.com.vn/citations?user=hZGzoFwAAAAJ&hl=en&authuser=3"> Van-Truong Nguyen</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:thanhnc.jaist.ac.jp">Email</a> &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?user=gnzxTKcAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/thanhnguyencanh">Github</a> &nbsp/&nbsp
                  <a href="https://www.linkedin.com/in/nguyencanhthanh/">LinkeIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile/thanh.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile/me2_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <heading>Recent News</heading>
                </td>
            </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
                <ul id="dataList">
              <!-- <li >[Jun 2022] I started my internship with Amazon Robotics</li> -->
              <li>[Sep 2024] Our paper on <a href="https://ieeexplore.ieee.org/abstract/document/9990495">Design of Deep Reinforcement Learning Approach for Traffic Signal Control at Three-way Crossroads </a> has been accepted to <a href="https://link.springer.com/journal/12469"> Public Transport</a>.</li>
              <li>[Dec 2024] I TA'ed <a href="https://syllabus.jaist.ac.jp/public/web/Syllabus/WebSyllabusSansho/UI/WSL_SyllabusSansho.aspx?P1=I213E500&P2=2024&P3=20240401">I213E: Discrete Signal Processing</a>. </li>
              <li>[Nov 2024] Our paper on <a href="https://ieeexplore.ieee.org/abstract/document/9990495">M-Calib: A Monocular 3D Object Localization using 2D Estimates for Industrial Robot Vision System </a> has been accepted to <a href="https://www.jamris.org/index.php/JAMRIS"> Journal of Automation, Mobile Robotics and Intelligent Systems (JAMRIS)</a>.</li>
              <li>[Oct 2024] I TA'ed <a href="https://syllabus.jaist.ac.jp/public/web/Syllabus/WebSyllabusSansho/UI/WSL_SyllabusSansho.aspx?P1=I116E400&P2=2024&P3=20240401">I116E: Fundamentals of Programming</a>. </li>
              <li>[Oct 2024] I started my Ph.D. journey in the <a href="https://www.jaist.ac.jp/english/areas/information-science.html"> School of Information Science </a> at <a href="https://www.jaist.ac.jp/english/"> JAIST</a>.</li>
              <li>[Sep 2024] Our paper on <a href="https://ieeexplore.ieee.org/abstract/document/9990495">Enhancing Social Robot Navigation with Integrated Motion Prediction and Trajectory Planning in Dynamic Human Environments </a> has been accepted to <a href="https://2024.iccas.org/"> ICCAS2024</a>.</li>
              <li>[Sep 2024] Our paper on <a href="https://ieeexplore.ieee.org/abstract/document/9990495">Toward Integrating Semantic-aware Path Planning and Reliable Localization for UAV Operations </a> has been accepted to <a href="https://2024.iccas.org/"> ICCAS2024</a>.</li>
              <li>[Aug 2024] Our paper on <a href="https://www.sciencedirect.com/science/article/pii/S2215098624001496">Optimal design and fabrication of frame structure for dual-arm service robots: An effective approach for humanâ€“robot interaction </a> has been publised to <a href="https://www.sciencedirect.com/journal/engineering-science-and-technology-an-international-journal"> Engineering Science and Technology, an International Journal (JESTECH)</a>.</li>
              <li>[Aug 2024] I have passed my qualifying exam and advanced to Ph.D. candidacy. &#x1F389;&#x1F389;&#x1F389;&#x1F389;&#x1F389;</li>
              <li>[Aug 2024] I sucessfully defened my <a href="https://dspace.jaist.ac.jp/dspace/handle/10119/19354?locale=en"> Msc. Thesis</a>.</li>            
              <li>[Nov 2023] Our paper on <a href="https://ieeexplore.ieee.org/abstract/document/10608973">Underwater Image Enhancement for Depth Estimation via Various Image Processing Techniques </a> has been accepted to <a href="https://icsse2024.web.nycu.edu.tw/"> ICSSE2024</a>.</li>
              <li>[Oct 2023] I started my Master journey in the <a href="https://www.jaist.ac.jp/english/areas/information-science.html"> School of Information Science </a> at <a href="https://www.jaist.ac.jp/english/"> JAIST</a>.</li>
              <li>[Sep 2023] Our paper on <a href="https://ieeexplore.ieee.org/abstract/document/10471804">Machine Learning-Based Malicious Vehicle Detection for Security Threats and Attacks in Vehicle Ad-Hoc Network (VANET) Communications </a> has been accepted to <a href="https://ieeexplore.ieee.org/xpl/conhome/10471760/proceeding"> RIVF2023</a>.</li>
              <li>[Sep 2023] Our paper on <a href="https://thanhnguyencanh.github.io/S3M_SLAM/">S3M: Semantic Segmentation Sparse Mapping for UAVs with RGB-D Camera </a> has been accepted to <a href="https://sice-si.org/SII2024/"> SII2024</a>.</li>
              <li>[Sep 2023] I am honered to receive VINIF Scholarship</li>
              <li>[Sep 2023] Our paper on <a href="https://ieeexplore.ieee.org/abstract/document/9990495">Object-Oriented Semantic Mapping for Reliable UAVs Navigation </a> has been accepted to <a href="https://ieeexplore.ieee.org/xpl/conhome/1802677/all-proceedings"> ICCAIS2023</a>.</li>
              <li>[Jul 2023] I am honered to receive Collaboration Scholarship from JAIST</li>
              <li>[Dec 2023] I TA'ed <a href="https://fet.uet.vnu.edu.vn/">FET: Programming robot with ROS; Human Machine Interface; PLC and Its Application; &amp; Mechanical Drawing</a>. </li>
              <li>[Dec 2022] I started my Master journey in the <a href="https://sites.google.com/view/aimpuet/home">Robotics Department</a> at <a href="https://uet.vnu.edu.vn/en/">University of Engineering and Technology, Vietnam National University, Vietnam</a>.</li>
              <li>[Nov 2023] I worked as a lecturer at the <a href="https://sites.google.com/view/aimpuet/home">Robotics Department</a> at <a href="https://uet.vnu.edu.vn/en/">University of Engineering and Technology, Vietnam National University, Vietnam</a>.</li>
              <li>[Sep 2022] Our paper on <a href="https://ieeexplore.ieee.org/abstract/document/9990495">Multisensor Data Fusion for Reliable Obstacle Avoidance </a> has been accepted to <a href="https://ieeexplore.ieee.org/xpl/conhome/9989531/proceeding"> ICCAIS2022</a></li>
              <li>[Sep 2022] I am honered to receive Best Student Thesis Awards and Exellent Student Award.</li>
              <li>[Aug 2022] I sucessfully defened my B.S Thesis.</li>
              <li>[Aug 2018] I started my B.S. journey in the <a href="https://sites.google.com/view/aimpuet/home">Robotics Department</a> at <a href="https://uet.vnu.edu.vn/en/">University of Engineering and Technology, Vietnam National University, Vietnam</a>.</li>
<!-- <input id="moreButton" type="button" value="More..." onclick="showMore()"/> -->
            </ul>
            
          </td>
        </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <heading>Research Interests</heading>
              <p>
                I am interested in robotics, machine learning, vision, and control. 
                My work focuses on robots' simultaneous localization and mapping, e.g. probablistic mapping, navigation and exploration, semantic slam, active slam and life-long slam; 
                and of their own dynamics model, e.g. robot dynamics learning, model-based reinforcement learning, and learning from demonstration. 
                I am also interested in modeling uncertainty in map representations and robots' dynamics for safe and active planning and control.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:10px;width:100%;vertical-align:middle">
            <heading>Awards & Professional Activities</heading>
            <ul id="dataList">
              <li> Best paper awards: 2023 IEEE International Conference on Research, Innovation and Vision for the Future (RIVF 2023) </li>
              <li> Instruction students to win Second place, Students Research Competition, 2023 VNU-University of Engineering and Technology </li>
              <li> Best Student Thesis Award, 2022 VNU-University of Engineering and Technology </li>
              <li> REV-ECIT Best paper award, 2022 Radio and Electronics Association of Vietnam (REV-ECIT 2022)</li>
              <li> First place, Students Research Competition, 2021 VNU-University of Engineering and Technology </li>
              <li> Reviewer:
                <a href="https://www.sciencedirect.com/journal/computers-and-electrical-engineering">Computers & electrical engineering</a>,
                <a href="https://link.springer.com/journal/11042">Multimedia tools and applications</a>,
                <a href="https://www.tandfonline.com/journals/tfls21"> All Life</a>,
                <a href="https://www.jamris.org/index.php/JAMRIS"> Journal of Automation, Mobile Robotics and Intelligent Systems</a>,
                <a href="https://www.sciencedirect.com/journal/engineering-science-and-technology-an-international-journal"> Engineering Science and Technology, an International Journal</a>
              </li>
            </ul>
          </td>
        </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:10px;width:100%;vertical-align:middle">
          <heading>Scholarships and Research grants</heading>
          <ul id="dataList"></ul>
            <li> KDDI Foundation Scholarship, 2024-2025 </li>
            <li> VinIF Scholarship for Master Programmer, Vingroup Innovation Foundation, 2023-2024 </li>
        </ul>
        </td>
      </tr>
    </tbody></table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:10px;width:100%;vertical-align:middle">
        <heading>Teaching</heading>
        <p> Robotics, Mobile Robotics, Algorithms for Intelligent Robots, Discrete Signal Processing </p>
        <p> Programming robot with ROS, Robotic Control, Human Machine Interface </p>
        <p> Mechanical Drawing, Electronics Engineering Practice, PLC and Its Application</p>
      </td>
    </tr>
    </tbody></table>
            
        
         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <heading>Publications</heading>
                </td>
            </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <b>Projects for active semantic slam</b>
                </td>
            </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <td style="padding:20px;width:30%;vertical-align:top">
          <video  width="220" muted autoplay loop>
            <source src="images/s3m/mp4/sim.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video>
          <!-- <video  width="220" muted autoplay loop>
            <source src="images/se3hamdl/mp4/lemniscate_learned_cut_fast_small.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video>
          <video  width="220" muted autoplay loop>
            <source src="images/se3hamdl/mp4/circle_learned_cut_fast_small.mp4" type="video/mp4">
            Your browser does not support the video tag. -->
            </video>
              <p><center>3D Semantic-aware SLAM</center></p>
        </td>
        <td style="padding:20px;width:80%;vertical-align:middle">
          <a href="https://thanhnguyencanh.github.io/S3M_SLAM/">
              <papertitle>S3M: Semantic Segmentation Sparse Mapping for UAVs with RGB-D Camera</papertitle>
          </a>
          <br>
          <strong>Thanh Nguyen Canh</strong>, Van-Truong Nguyen, Xiem HoangVan, Armagan Elibol,
          <a href="https://www.jaist.ac.jp/robot/">Nak Young Chong</a>
                        <br> 
          <em>Conference version, accepted to <a href="https://sice-si.org/SII2024/"> SII </a></em>, 2024. <br>
          <a href="https://thanhnguyencanh.github.io/S3M_SLAM/">website</a> /
          <a href="https://thanhnguyencanh.github.io/S3M_SLAM/">video</a> /
          <a href="https://arxiv.org/abs/2401.08134">arxiv</a> /
          <a href="https://github.com/thanhnguyencanh/S3M_SLAM">code</a>
          <p></p>
          <p> This paper presents a novel approach to address challenges in semantic information extraction and utilization within UAV operations. Our system integrates state-of-the-art visual SLAM to estimate a comprehensive 6-DoF pose and advanced object segmentation methods at the back end. To improve the computational and storage efficiency of the framework, we adopt a streamlined voxel-based 3D map representation - OctoMap to build a working system. Furthermore, the fusion algorithm is incorporated to obtain the semantic information of each frame from the front-end SLAM task, and the corresponding point. By leveraging semantic information, our framework enhances the UAV's ability to perceive and navigate through indoor spaces, addressing challenges in pose estimation accuracy and uncertainty reduction. Through Gazebo simulations, we validate the efficacy of our proposed system and successfully embed our approach into a Jetson Xavier AGX unit for real-world applications.</p>
          <!-- <video  width="180" muted autoplay loop>
            <source src="images/se3hamdl/mp4/data_collection_fast1_small.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video>
          <video  width="180" muted autoplay loop>
            <source src="images/se3hamdl/mp4/data_collection_fast2_small.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video>
          <video  width="180" muted autoplay loop>
            <source src="images/se3hamdl/mp4/data_collection_fast3_small.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video>
            <p><center>Data collection from manual flights</center></p> -->
        </td>
      </tr>

      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <td style="padding:20px;width:30%;vertical-align:top">
        <video  width="220" muted autoplay loop>
          <source src="images/s3m/mp4/sim.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video>
        <!-- <video  width="220" muted autoplay loop>
          <source src="images/se3hamdl/mp4/lemniscate_learned_cut_fast_small.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video>
        <video  width="220" muted autoplay loop>
          <source src="images/se3hamdl/mp4/circle_learned_cut_fast_small.mp4" type="video/mp4">
          Your browser does not support the video tag. -->
          </video>
            <p><center>3D Semantic-aware SLAM</center></p>
      </td>
      <td style="padding:20px;width:80%;vertical-align:middle">
        <a href="https://thanhnguyencanh.github.io/S3M_SLAM/">
            <papertitle>S3M: Semantic Segmentation Sparse Mapping for UAVs with RGB-D Camera</papertitle>
        </a>
        <br>
        <strong>Thanh Nguyen Canh</strong>, Van-Truong Nguyen, Xiem HoangVan, Armagan Elibol,
        <a href="https://www.jaist.ac.jp/robot/">Nak Young Chong</a>
                      <br> 
        <em>Conference version, accepted to <a href="https://sice-si.org/SII2024/"> SII </a></em>, 2024. <br>
        <a href="https://thanhnguyencanh.github.io/S3M_SLAM/">website</a> /
        <a href="https://thanhnguyencanh.github.io/S3M_SLAM/">video</a> /
        <a href="https://arxiv.org/abs/2401.08134">arxiv</a> /
        <a href="https://github.com/thanhnguyencanh/S3M_SLAM">code</a>
        <p></p>
        <p> This paper presents a novel approach to address challenges in semantic information extraction and utilization within UAV operations. Our system integrates state-of-the-art visual SLAM to estimate a comprehensive 6-DoF pose and advanced object segmentation methods at the back end. To improve the computational and storage efficiency of the framework, we adopt a streamlined voxel-based 3D map representation - OctoMap to build a working system. Furthermore, the fusion algorithm is incorporated to obtain the semantic information of each frame from the front-end SLAM task, and the corresponding point. By leveraging semantic information, our framework enhances the UAV's ability to perceive and navigate through indoor spaces, addressing challenges in pose estimation accuracy and uncertainty reduction. Through Gazebo simulations, we validate the efficacy of our proposed system and successfully embed our approach into a Jetson Xavier AGX unit for real-world applications.</p>
      </td>
    </tr>

    </tbody></table>

       

       <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                    <b>Projects for robot learning</b>
                </td>
            </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <td style="padding:10px;width:100%;vertical-align:middle">
                  <b>Projects for reliable localization and safety path planing</b>
              </td>
          </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
                <b>Projects for 3D robot calibration</b>
            </td>
        </tr>
    </tbody></table>
        
        


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
              <p style="text-align:right;font-size:small;">
                <a href='https://clustrmaps.com/site/1b3ld'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=160&t=tt&d=w2RjAUmBU2UblwclHzT7CYrfKyZjpWjsOPSaxaDFbgI'/></a>
                <br /> 
                Template borrowed from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
